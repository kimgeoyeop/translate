from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
model = AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-ko-en")

# ì‚¬ìš©ì ì…ë ¥
src_text = input("ë²ˆì—­í•  í•œêµ­ì–´ ë¬¸ì¥ ì…ë ¥: ")

# í† í¬ë‚˜ì´ì¦ˆ
inputs = tokenizer(src_text, return_tensors="pt")

# ë²ˆì—­ ì‹¤í–‰
translated = model.generate(**inputs, max_length=40)

# ê²°ê³¼ ë””ì½”ë”©
result = tokenizer.decode(translated[0], skip_special_tokens=True)

print("\nğŸ“˜ ë²ˆì—­ ê²°ê³¼:")
print(result)
